{"cells":[{"cell_type":"markdown","source":["### Multi label classifiation of news into its category using Mutlinomial Naive Bayes\n\nThis classifier treats each occurrence of a word as an event. Each of the words' conditional probability distribution is assumed to be multinomial. This ref https://syncedreview.com/2017/07/17/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation/ can be a good refresher of the MultiNB working on text classification problem like the present use case.\n\nLaplace Smoothing is to assign some fail-safe probability to missing tokens in news item sentence, otherwise its container sentences probability gets squashed to zero!\n\nPipeline stages: -\n* Term frequency: Use either CountVectorizer or HashingTF\n  * [HashingTF] The transformer hashes token & applies modulo % 'numFeatures' to get unique index => have descently big 'numFeatures' to avoid collission resulting in erroneous TF of some important token => 'numFeatures' default 2^^18\n* Inverse Doc Freq (IDF): It operates on TF\n\nImportant Notes: -\n* The UCI News Aggregator dataset has been taken from https://www.kaggle.com/uciml/news-aggregator-dataset. It contains headlines, URLs, and categories for 422,937 news stories collected by a web aggregator between March 10th, 2014 and August 10th, 2014. Upload csv file to Databricks FileStore through \"databricks >> Import & Explore Data\".\n* This notebook has been at https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1044241664895185/3279643061129108/3281307886843282/latest.html.\n* This solution has been tried on Databricks Community!"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline \nfrom pyspark.ml.feature import Tokenizer, CountVectorizer, StringIndexer, RegexTokenizer, StopWordsRemover, HashingTF, IDF, IndexToString\nfrom pyspark.sql.functions import col, udf,regexp_replace,isnull, countDistinct\nfrom pyspark.sql.types import StringType,IntegerType\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["news = spark.read.csv(\"/FileStore/tables/uci_news_aggregator-e0002.csv\", header='True', inferSchema='True')\n#news.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["news = news.select(\"TITLE\", \"CATEGORY\")\nnews = news.dropna()\n#news.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["#news.show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["#news.agg(*(countDistinct(col(c)).alias(c) for c in news.columns)).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# 'category' column requires just categorization which is \n\nindexer = StringIndexer(inputCol=\"CATEGORY\", outputCol=\"label\")\nnews = indexer.fit(news).transform(news)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["(news_train, news_test) = news.randomSplit([0.8, 0.2], seed = 12345)\n#print(news_train.count(), news_test.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Pipeline labelCol default is 'label' & featuresCol default is 'features'\n\n#categoryIndexer = StringIndexer(inputCol=\"CATEGORY\", outputCol=\"label\")\n\ntokenizer = Tokenizer(inputCol=\"TITLE\", outputCol=\"words\")\nwordsRemover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"words_cleaned\")\n\ncv = CountVectorizer(inputCol=wordsRemover.getOutputCol(), outputCol=\"words_tf\")\n#hashingTF = HashingTF(inputCol=wordsRemover.getOutputCol(), outputCol=\"title_cleaned_hashed\")\n\nidf = IDF(minDocFreq=5, inputCol=cv.getOutputCol(), outputCol=\"features\")\n\nnb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# tokenizer, wordsRemover & hashingTF are of type Tranasformer\n# tfidf stage involves both Estimator & Transform (it used in standalone mode then it should be used as per below\n#               idf = IDF().fit(tf)\n#               tfidf = idf.transform(tf))\n# lr stage involves only Estimator\n\npipeline = Pipeline(stages=[tokenizer, wordsRemover, cv, idf, nb])\n\nmodel = pipeline.fit(news_train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["nb_predictions = model.transform(news_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["#nb_predictions.select(\"prediction\", \"label\", \"features\").show(20)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["nb_accuracy = evaluator.evaluate(nb_predictions)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["print(\"Accuracy of NaiveBayes is = %g\" % (nb_accuracy))\nprint(\"Test Error of NaiveBayes = %g \" % (1.0 - nb_accuracy))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of NaiveBayes is = 0.922657\nTest Error of NaiveBayes = 0.077343 \n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["Misc notes: - \n* [TODO] Attempted to chain categoryIndexer pre-processing on CATEGORY column but \"...Failed to execute user defined function($anonfun$9: (string) =&gt; double)...\"."],"metadata":{}}],"metadata":{"name":"MultiNB_nlp_news_classification","notebookId":3279643061129108},"nbformat":4,"nbformat_minor":0}
