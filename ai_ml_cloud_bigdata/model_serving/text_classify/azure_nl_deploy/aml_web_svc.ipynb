{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collection of code blocks\n",
    "\n",
    "* Get Azure Oauth to use desired Azure Subscription\n",
    "* Create Azure ML Service Workspace instance\n",
    "* Register available model files into Azure ML Service Workspace as Models which will be used during Prediction Serving\n",
    "* Scoring code to be emitted into 'score.py'\n",
    "* Create Docker Image, deployment of container instances, deployment of Azure ML Web Service for scoring/prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "import pickle, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure to use the correct Azure Subscription\n",
    "# As this work is being initiated from Jupyter Notebook from Azure portal, it needs to be Authorized through Device Assisted Azure Login\n",
    "\n",
    "!az account set -s <subscription-id>\n",
    "!az login\n",
    "\n",
    "# You can expect to see this below instruction for completing Azure login & oauth\n",
    "#\n",
    "# To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code F2K6SGE5K to authenticate.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Workspace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-06a355776449>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Workspace instance is being created from config.json (which is expected to have subscription-id, resource-group-name & azure-ml-service-workspace-name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Workspace' is not defined"
     ]
    }
   ],
   "source": [
    "# Workspace instance is being created from config.json (which is expected to have subscription-id, resource-group-name & azure-ml-service-workspace-name)\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model classifier_model\n",
      "Registering model vocab\n"
     ]
    }
   ],
   "source": [
    "# Below 2 models are from offline ML Model Training in .pkl format\n",
    "# Here these model files are being registered as Model in Azure ML Service Workspace\n",
    "\n",
    "model = Model.register(model_path = \"classifier_model.pkl\",\n",
    "                       model_name = \"classifier_model\",\n",
    "                       tags = {\"key\": \"0.1\"},\n",
    "                       description = \"classifier_model\",\n",
    "                       workspace = ws)\n",
    "\n",
    "vocab = Model.register(model_path = \"vocab.pkl\",\n",
    "                       model_name = \"vocab\",\n",
    "                       tags = {\"key\": \"0.1\"},\n",
    "                       description = \"vocab\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "# Scoring code to be deployed in Azure ML Service and it will be used to serve Prediction through REST Web Service\n",
    "\n",
    "%%writefile score.py\n",
    "import pickle, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model, vocab, txt_filters\n",
    "    \n",
    "    txt_filters = [lambda x: x.lower(), strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short]\n",
    "    \n",
    "    model_path = Model.get_model_path(model_name = \"classifier_model\")\n",
    "    with open(model_path, \"rb\") as f_model:\n",
    "        model = pickle.load(f_model)\n",
    "        \n",
    "    vocab_path = Model.get_model_path(model_name = \"vocab\")\n",
    "    with open(vocab_path, \"rb\") as f_vocab:\n",
    "        vocab = pickle.load(f_vocab)\n",
    "\n",
    "        \n",
    "def process_input(row):\n",
    "    input_merged = row['Assignment Name'] + ' ' + row['School Category']\n",
    "    \n",
    "    # gensim's preprocess_string through series of txt_filters which generates tokens array\n",
    "    input_processed_tokens = \" \".join(preprocess_string(input_merged, txt_filters))\n",
    "    \n",
    "    return input_processed_tokens\n",
    "\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "    \n",
    "def run(raw_data):\n",
    "    try:\n",
    "        input_json = json.loads(raw_data)\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(input_json, orient='columns')\n",
    "        df['processed_input'] = df.apply(lambda row: process_input(row), axis=1)\n",
    "        \n",
    "        count_vect = CountVectorizer(vocabulary=vocab)\n",
    "        count_vect._validate_vocabulary()\n",
    "        \n",
    "        prediction = model.predict(count_vect.transform(df['processed_input']))\n",
    "        \n",
    "        # Overriding ML Model predicted label with rule-based decision\n",
    "        labels_dict = {}\n",
    "        labels_dict['assignment'] = 0\n",
    "        labels_dict['quiz'] = 1\n",
    "        labels_dict['homework'] = 2\n",
    "        labels_dict['test'] = 3\n",
    "        labels_dict['extra credit'] = 4\n",
    "\n",
    "        arr_labels = ['assignment', 'quiz', 'homework', 'test', 'extra credit']\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            label_match_school_category = re.search('assignment|quiz|homework|test|extra credit', row['School Category'].lower())\n",
    "            label_match_assignment_name = re.search('assignment|quiz|homework|test|extra credit', row['Assignment Name'].lower()) \n",
    "            predicted_match_school_category = re.search(arr_labels[prediction[index]], row['School Category'].lower())\n",
    "            predicted_match_assignment_name = re.search(arr_labels[prediction[index]], row['Assignment Name'].lower())     \n",
    "            if label_match_school_category and (label_match_assignment_name is None) and (predicted_match_school_category is None):\n",
    "                prediction[index] = labels_dict[label_match_school_category.group()]\n",
    "            elif label_match_assignment_name and (label_match_school_category is None) and (predicted_match_assignment_name is None):\n",
    "                prediction[index] = labels_dict[label_match_assignment_name.group()]\n",
    "        \n",
    "        out_json = json.dumps(prediction, cls=NumpyEncoder)\n",
    "        return out_json\n",
    "    \n",
    "    except Exception as e:\n",
    "        msg_exception = str(e)\n",
    "        return json.dumps({\"error\": msg_exception})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below code blocks actually perform the following steps\n",
    "* Create Docker Container Images with required Conda, Python & Dependencies\n",
    "* Creates 'text-classifier' Deployment instance - this actually points to ACI (Azure Container Instances) managed multiple Container Instances\n",
    "* Deploys 'text-classifier' Azure ML Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myenv.yml'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_conda_package(\"gensim\")\n",
    "myenv.save_to_file(\".\", \"myenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Image creation operation finished for image text-classifier:5, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running......................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\", \n",
    "                                    runtime = \"python\", \n",
    "                                    conda_file = \"myenv.yml\")\n",
    "\n",
    "service = Webservice.deploy_from_model(name = \"text-classifier\",\n",
    "                                       deployment_config = aci_config,\n",
    "                                       models = [model, vocab],\n",
    "                                       image_config = image_config,\n",
    "                                       workspace = ws)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0a5a21860103>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Checking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWebservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mservices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWebservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azureml'"
     ]
    }
   ],
   "source": [
    "# Fetching Scoring URL of the deployed Azure ML Web Service\n",
    "\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "services = Webservice.list(ws)\n",
    "print(services[0].scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate for fetching Scoring/Prediction URL of the deployed Azure ML Web Service\n",
    "\n",
    "service = Webservice(workspace=ws, name='text-classifier')\n",
    "print(service.scoring_uri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
