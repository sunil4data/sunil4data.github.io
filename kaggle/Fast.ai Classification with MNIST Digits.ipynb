{
  "cells": [
    {
      "metadata": {
        "_uuid": "c9a8d5aabc174a6a40fc2e5e1cb6e86a04d5cd1e"
      },
      "cell_type": "markdown",
      "source": "## Fast.ai Multi Label Image Classification of MNIST Handwritten Digits\n\n#### Sunil Kumar\n\nThis solution to multi-labels classification is pretty much same as that for binary classification as in https://www.kaggle.com/suniliitb96/fast-ai-learning-through-cats-dogs. This solution utilizes Image Augmentation duing training and the same augmentation during prediction on test images too.\n\nWithout much digging around as what is the difference between Kaggle MNIST Digits Recognizer dataset (42k train & 28k test) & Keras MNIST Digits dataset (60k labeled train & 10k labeled test), I borrowed the idea [Ref #2] of importing bigger dataset from Keras for training to help optimize loss & accuracy - as both dataset are definitely related and for the same purpose!\n\n##### Fast.ai specific terms: - \n* It interprets problem classification type whether it is binary -or- multi-labels from training label values. \n* Plain-nets & Res-nets expects its input of certain size. ResNet50 expects batch_size x 224 x 224 x 3 data buffer in each mini batch. Fast.ai transforms input images and augmented intermediate images of arbitrary sizes using PyTorch torchvision API along with specified image augmentations.\n* Fast.ai SGDR is actually Cyclical Learning, a.k.a., Learning Rate Annealing with Warm Restart. This approach helps in come out of any possible local minima.\n* Fast.ai Differential Learning Rate is for fine tuning pre-trained weights of ResNet\n* If training employs image augmentations (through 'aug_tfms' in 'ImageClassifierData', then learned model must use 'learn.TTA(...)' than plain 'learn.predict(...)'\n\n##### Few points to note: -\n* As all pre-trained plain-net (LeNet, AlexNet, .., GoogleNet) or ResNet* are trained on color images and hence they expect our images too in color. Hence, we colorize our grayscale images by replicating gray value into RGB channels."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0d6caeb8b1aa1f87fd7c0720dad30ae357dc4207"
      },
      "cell_type": "code",
      "source": "%reload_ext autoreload\n%autoreload 2\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport cv2\nimport os\n\nfrom keras.datasets import mnist\n\nfrom fastai.conv_learner import *\nfrom fastai.plots import *\n\nfrom sklearn.model_selection import train_test_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "os.listdir(\"../input\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d57f5f1e8d39925146e85826bfd7fc7f2da8512"
      },
      "cell_type": "code",
      "source": "# 42k train & 28k test images of size 28x28 are available in row-per-image flattened csv\ntrain_img_lbl_kaggle = pd.read_csv(\"../input/train.csv\")\ntest_img_kaggle = pd.read_csv(\"../input/test.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6a7ae941db3ba8b1f9f194d6a35615c35c2ae48e"
      },
      "cell_type": "code",
      "source": "# train's 1st column is label\ntrain_img_kaggle = train_img_lbl_kaggle.iloc[:, 1:]\ntrain_lbl_kaggle = train_img_lbl_kaggle.iloc[:, 0:1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "626b7c14a316350f3230e2db904605d0a539d1ce"
      },
      "cell_type": "code",
      "source": "train_img_kaggle = train_img_kaggle.values.reshape(-1, 28, 28)\ntest_img_kaggle = test_img_kaggle.values.reshape(-1, 28, 28)\n\n(train_img_kaggle.shape, test_img_kaggle.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1384950c2939277b6ccc196778f9594829c89e4"
      },
      "cell_type": "code",
      "source": "(train_img_keras, train_lbl_keras), (test_img_keras, test_lbl_keras) = mnist.load_data()\ntrain_lbl_keras = train_lbl_keras.reshape(60000, 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98f167452b63ad74c030a1346771390db6fb5c53"
      },
      "cell_type": "code",
      "source": "(train_lbl_kaggle.shape, train_lbl_keras.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75474a6121e91ff452755307b36165c3ca964df1"
      },
      "cell_type": "code",
      "source": "train_img_all = np.concatenate((train_img_kaggle, train_img_keras), axis=0)\ntrain_lbl_all = np.concatenate((train_lbl_kaggle, train_lbl_keras), axis=0)\n(train_img_all.shape, train_lbl_all.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e67df744473b4ae612c892479cddee3fa85a62e6"
      },
      "cell_type": "code",
      "source": "# Converting images from 8-bit to 24-bit \ntrain_img_all = np.stack((train_img_all,)*3, axis = -1).astype('float32')\ntest_img_kaggle = np.stack((test_img_kaggle,)*3, axis = -1).astype('float32')\n\n(train_img_all.shape, test_img_kaggle.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "81a03538f1e272e89a8f51d868f9b38e0e26952a"
      },
      "cell_type": "code",
      "source": "train_img, val_img, train_lbl, val_lbl = train_test_split(train_img_all, train_lbl_all, train_size=0.8, random_state=1, stratify=train_lbl_all)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23712cb7b5febe06684d33122ef950a403ea895a"
      },
      "cell_type": "code",
      "source": "train_lbl = train_lbl.flatten()\nval_lbl = val_lbl.flatten()\n(train_lbl.shape, val_lbl.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d6954f56e69a26223f29194d63d82537be4da3e"
      },
      "cell_type": "code",
      "source": "# Though 30' random rotation loos quite large, it gave good results with limited samples\n# This relatively large random roation was tried to check if it helps avoid mis-labeling\n\narch = resnet50\nsz = 28\nclasses = np.unique(train_lbl)\ndata = ImageClassifierData.from_arrays(path = \"/tmp\",\n                                     trn = (train_img, train_lbl),\n                                     val = (val_img, val_lbl),\n                                     classes = train_lbl,\n                                     test = test_img_kaggle,\n                                     tfms = tfms_from_model(arch, sz, aug_tfms = [RandomRotateZoom(deg=10, zoom=1.1, stretch=1.0)]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58e3f9e892e2ba8a981eda8673dd072a067c442c"
      },
      "cell_type": "code",
      "source": "learn = ConvLearner.pretrained(arch, data, precompute = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "236f28998add9e5af7f84c7122eb4f90c8b00156"
      },
      "cell_type": "code",
      "source": "###\n### Search for suitable, i.e., best Learning Rate for our-newly-added-Last Layer (as we have used 'precompute=True', i.e., ResNet50-minus-its-last-layer weights are being re-used as is)\n###\n#lrf=learn.lr_find()\n#learn.sched.plot_lr()\n\n#learn.sched.plot()\n\n###\n### Use the identified best Learning Rate for our-newly-added-Last Layer\n### Note that even without running above 3 lines of Learning Rate Finder, it is well known that best learning rate is 0.01 even for MNIST Digits 28x28 images\n###\n#learn.fit(0.01, 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1eda4877564e503832c65e23dab31350741f0d23"
      },
      "cell_type": "code",
      "source": "###\n### SGDR (SGD with warm Resrart): fast.ai uses half Cosine shape decay (start with 0.01 & decay till 0) of LR during each epoch and then it restarts with 1e-02\n###\nlearn.fit(1e-2, 10, cycle_len = 1)\nlearn.sched.plot_lr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5bf65c8ab725ae07eb5996382685abbb50a2eedd",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "###\n### Continue from Last Layer learned model with PreCompute=TRUE\n### Unfreeze all layers (all weights learned so far are retained) => it sets PreCompute=FALSE making all layers learnable\n### Effectively, the network weights are intialized as (ResNet-minus-last-layer with its original pre-trained weight & Last Layer as per above model learning while keeping ResNet as frozen)\n### Now, all layers are FURTHER learnable\n###\nlearn.unfreeze()\n\n# Differential LR (above identified best LR for last layer, x0.1 to middle layer, x0.01 to inner layer)\nlr=np.array([1e-4, 1e-3, 1e-2])\n\nlearn.fit(lr, 3, cycle_len = 1, cycle_mult =  2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5638e1b715aa17e99b4f02f605e3ffb488aecc65"
      },
      "cell_type": "code",
      "source": "learn.sched.plot_lr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d926a4626877b9dfd0c7b5438ccff89cede1987"
      },
      "cell_type": "code",
      "source": "#temp = learn.predict(is_test = True)\n#pred = np.argmax(temp, axis = 1)\n\nlog_preds, y = learn.TTA(is_test=True)\nprobs_test = np.mean(np.exp(log_preds), 0)\n\npred_df = pd.DataFrame(probs_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "acc53cd1efff963724ec7c4a2beea9157f20f7b3"
      },
      "cell_type": "code",
      "source": "pred_df = pred_df.assign(Label = pred_df.values.argmax(axis=1))\npred_df = pred_df.assign(ImageId = pred_df.index.values + 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4af41c4136c856e7842034c88db4c80f136c6a65"
      },
      "cell_type": "code",
      "source": "submit_df = pred_df[['ImageId', 'Label']]\nsubmit_df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd9f2ea9df4084ebdceb5d3fd352f588a6640cff",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "f, ax = plt.subplots(5, 5, figsize = (15, 15))\n\nfor i in range(0,25):\n    ax[i//5, i%5].imshow(test_img_kaggle[i].astype('int'))\n    ax[i//5, i%5].axis('off')\n    ax[i//5, i%5].set_title(\"Predicted:{}\".format(submit_df.Label[i]))    \n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b8a62988620279d73e5485085de7aa97ed85356"
      },
      "cell_type": "code",
      "source": "submit_df.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8d2ce42bb9649f196b99417227aa3807c606c77d"
      },
      "cell_type": "markdown",
      "source": "### References\n\n1. [Fast.ai Learning through Cats & Dogs Image Binary Classification](https://www.kaggle.com/suniliitb96/fast-ai-learning-through-cats-dogs)\n2. [MNIST 99.74% with Convoluted NN and Keras](https://www.kaggle.com/drscarlat/mnist-99-74-with-convoluted-nn-and-keras)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}