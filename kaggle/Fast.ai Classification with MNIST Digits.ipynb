{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c9a8d5aabc174a6a40fc2e5e1cb6e86a04d5cd1e"
   },
   "source": [
    "## Fast.ai Multi Label Image Classification of MNIST Handwritten Digits\n",
    "\n",
    "#### Sunil Kumar\n",
    "\n",
    "Its working setup, i.e., Kernel is available in Kaggle at https://www.kaggle.com/suniliitb96/fast-ai-classification-with-mnist-digits\n",
    "\n",
    "This solution to multi-labels classification is pretty much same as that for binary classification as in https://www.kaggle.com/suniliitb96/fast-ai-learning-through-cats-dogs. This solution utilizes Image Augmentation duing training and the same augmentation during prediction on test images too.\n",
    "\n",
    "##### Fast.ai specific terms: - \n",
    "* It interprets problem classification type whether it is binary -or- multi-labels from training label values. \n",
    "* Plain-nets & Res-nets expects its input of certain size. ResNet50 expects batch_size x 224 x 224 x 3 data buffer in each mini batch. Fast.ai transforms input images and augmented intermediate images of arbitrary sizes using PyTorch torchvision API along with specified image augmentations.\n",
    "* Fast.ai SGDR is actually Cyclical Learning, a.k.a., Learning Rate Annealing with Warm Restart. This approach helps in come out of any possible local minima.\n",
    "* Fast.ai Differential Learning Rate is for fine tuning pre-trained weights of ResNet\n",
    "* If training employs image augmentations (through 'aug_tfms' in 'ImageClassifierData', then learned model must use 'learn.TTA(...)' than plain 'learn.predict(...)'\n",
    "\n",
    "##### Few points to note: -\n",
    "* As all pre-trained plain-net (LeNet, AlexNet, .., GoogleNet) or ResNet* are trained on color images and hence they expect our images too in color. Hence, we colorize our grayscale images by replicating gray value into RGB channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d6caeb8b1aa1f87fd7c0720dad30ae357dc4207"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.plots import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "os.listdir(\"../input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d57f5f1e8d39925146e85826bfd7fc7f2da8512"
   },
   "outputs": [],
   "source": [
    "# 42k train & 28k test images of size 28x28 are available in row-per-image flattened csv\n",
    "train_img_lbl = pd.read_csv(\"../input/train.csv\")\n",
    "test_img = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a7ae941db3ba8b1f9f194d6a35615c35c2ae48e"
   },
   "outputs": [],
   "source": [
    "# train's 1st column is label\n",
    "train_img = train_img_lbl.iloc[:, 1:]\n",
    "train_label = train_img_lbl.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "626b7c14a316350f3230e2db904605d0a539d1ce"
   },
   "outputs": [],
   "source": [
    "train_img = train_img.values.reshape(-1, 28, 28)\n",
    "test_img = test_img.values.reshape(-1, 28, 28)\n",
    "\n",
    "(train_img.shape, test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e67df744473b4ae612c892479cddee3fa85a62e6"
   },
   "outputs": [],
   "source": [
    "# Converting images from 8-bit to 24-bit \n",
    "train_img = np.stack((train_img,)*3, axis = -1).astype('float32')\n",
    "test_img = np.stack((test_img,)*3, axis = -1).astype('float32')\n",
    "\n",
    "(train_img.shape, test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81a03538f1e272e89a8f51d868f9b38e0e26952a"
   },
   "outputs": [],
   "source": [
    "train_img, val_img, train_lbl, val_lbl = train_test_split(train_img, train_label, train_size=0.8, random_state=1, stratify=train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23712cb7b5febe06684d33122ef950a403ea895a"
   },
   "outputs": [],
   "source": [
    "train_lbl = train_lbl.values.flatten()\n",
    "val_lbl = val_lbl.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d6954f56e69a26223f29194d63d82537be4da3e"
   },
   "outputs": [],
   "source": [
    "# Though 30' random rotation loos quite large, it gave good results with limited samples\n",
    "# This relatively large random roation was tried to check if it helps avoid mis-labeling\n",
    "\n",
    "arch = resnet50\n",
    "sz = 28\n",
    "classes = np.unique(train_lbl)\n",
    "data = ImageClassifierData.from_arrays(path = \"/tmp\",\n",
    "                                     trn = (train_img, train_lbl),\n",
    "                                     val = (val_img, val_lbl),\n",
    "                                     classes = train_lbl,\n",
    "                                     test = test_img,\n",
    "                                     tfms = tfms_from_model(arch, sz, aug_tfms = [RandomRotateZoom(deg=30, zoom=1.2, stretch=1.0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58e3f9e892e2ba8a981eda8673dd072a067c442c"
   },
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "236f28998add9e5af7f84c7122eb4f90c8b00156"
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Search for suitable, i.e., best Learning Rate for our-newly-added-Last Layer (as we have used 'precompute=True', i.e., ResNet50-minus-its-last-layer weights are being re-used as is)\n",
    "###\n",
    "#lrf=learn.lr_find()\n",
    "#learn.sched.plot_lr()\n",
    "\n",
    "#learn.sched.plot()\n",
    "\n",
    "###\n",
    "### Use the identified best Learning Rate for our-newly-added-Last Layer\n",
    "### Note that even without running above 3 lines of Learning Rate Finder, it is well known that best learning rate is 0.01 even for MNIST Digits 28x28 images\n",
    "###\n",
    "#learn.fit(0.01, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1eda4877564e503832c65e23dab31350741f0d23"
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SGDR (SGD with warm Resrart): fast.ai uses half Cosine shape decay (start with 0.01 & decay till 0) of LR during each epoch and then it restarts with 1e-02\n",
    "###\n",
    "learn.fit(1e-2, 10, cycle_len = 1)\n",
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5bf65c8ab725ae07eb5996382685abbb50a2eedd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Continue from Last Layer learned model with PreCompute=TRUE\n",
    "### Unfreeze all layers (all weights learned so far are retained) => it sets PreCompute=FALSE making all layers learnable\n",
    "### Effectively, the network weights are intialized as (ResNet-minus-last-layer with its original pre-trained weight & Last Layer as per above model learning while keeping ResNet as frozen)\n",
    "### Now, all layers are FURTHER learnable\n",
    "###\n",
    "learn.unfreeze()\n",
    "\n",
    "# Differential LR (above identified best LR for last layer, x0.1 to middle layer, x0.01 to inner layer)\n",
    "lr=np.array([1e-4, 1e-3, 1e-2])\n",
    "\n",
    "learn.fit(lr, 3, cycle_len = 1, cycle_mult =  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5638e1b715aa17e99b4f02f605e3ffb488aecc65"
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d926a4626877b9dfd0c7b5438ccff89cede1987"
   },
   "outputs": [],
   "source": [
    "#temp = learn.predict(is_test = True)\n",
    "#pred = np.argmax(temp, axis = 1)\n",
    "\n",
    "log_preds, y = learn.TTA(is_test=True)\n",
    "probs_test = np.mean(np.exp(log_preds), 0)\n",
    "\n",
    "pred_df = pd.DataFrame(probs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "acc53cd1efff963724ec7c4a2beea9157f20f7b3"
   },
   "outputs": [],
   "source": [
    "pred_df = pred_df.assign(Label = pred_df.values.argmax(axis=1))\n",
    "pred_df = pred_df.assign(ImageId = pred_df.index.values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4af41c4136c856e7842034c88db4c80f136c6a65"
   },
   "outputs": [],
   "source": [
    "submit_df = pred_df[['ImageId', 'Label']]\n",
    "submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd9f2ea9df4084ebdceb5d3fd352f588a6640cff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(5, 5, figsize = (15, 15))\n",
    "\n",
    "for i in range(0,25):\n",
    "    ax[i//5, i%5].imshow(test_img[i].astype('int'))\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    ax[i//5, i%5].set_title(\"Predicted:{}\".format(submit_df.Label[i]))    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b8a62988620279d73e5485085de7aa97ed85356"
   },
   "outputs": [],
   "source": [
    "submit_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d2ce42bb9649f196b99417227aa3807c606c77d"
   },
   "source": [
    "### References\n",
    "\n",
    "1. [Fast.ai Learning through Cats & Dogs Image Binary Classification](https://www.kaggle.com/suniliitb96/fast-ai-learning-through-cats-dogs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
